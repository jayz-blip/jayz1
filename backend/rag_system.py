import os
import pandas as pd
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from typing import List, Tuple, Optional, Dict
import re
from bs4 import BeautifulSoup
import openai
from dotenv import load_dotenv
from datetime import datetime

load_dotenv()

class RAGSystem:
    def __init__(self):
        # ëª¨ë¸ê³¼ ë°ì´í„°ëŠ” ì§€ì—° ë¡œë”© (ë©”ëª¨ë¦¬ ì ˆì•½)
        self.embedding_model = None
        db_path = os.path.join(os.path.dirname(__file__), "..", "chroma_db")
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=db_path
        ))
        self.collection = None
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.use_openai = bool(self.openai_api_key)
        
        # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ì €ì¥ (ê³ ê°ì‚¬ë³„ ê²€ìƒ‰ìš©)
        self.df_original = None
        self.df_comment = None
        
        # ì´ˆê¸°í™” ì™„ë£Œ í”Œë˜ê·¸
        self._initialized = False
    
    def _ensure_initialized(self):
        """í•„ìš” ì‹œ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        if not self._initialized:
            print("ğŸ”„ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            # ëª¨ë¸ ë¡œë“œ
            if self.embedding_model is None:
                print("ğŸ“¥ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
                print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
            # ë°ì´í„° ë¡œë“œ ë° ë²¡í„°í™”
            self.load_data()
            self._initialized = True
            print("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def clean_html(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if pd.isna(text) or text == "":
            return ""
        soup = BeautifulSoup(str(text), 'html.parser')
        text = soup.get_text()
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def load_data(self):
        """CSV íŒŒì¼ ë¡œë“œ ë° ë²¡í„° DBì— ì €ì¥"""
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ë° ì¬ìƒì„±
        try:
            self.client.delete_collection("ppm_knowledge")
        except:
            pass
        
        self.collection = self.client.create_collection(
            name="ppm_knowledge",
            metadata={"hnsw:space": "cosine"}
        )
        
        documents = []
        metadatas = []
        ids = []
        
        # ì›ê¸€ ë°ì´í„° ë¡œë“œ
        try:
            csv_path_original = os.path.join(os.path.dirname(__file__), "..", "20251125_PPMí•™ìŠµìš©ë°ì´í„°_ì›ê¸€.csv")
            self.df_original = pd.read_csv(csv_path_original, encoding='utf-8')
            print(f"ì›ê¸€ ë°ì´í„°: {len(self.df_original)}ê°œ ë¡œë“œë¨")
            
            for idx, row in self.df_original.iterrows():
                content = self.clean_html(row.get('content', ''))
                subject = self.clean_html(row.get('subject', ''))
                name = row.get('name', '')
                
                if content and len(content) > 10:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    text = f"ì œëª©: {subject}\në‚´ìš©: {content}"
                    if name:
                        text = f"[{name}] {text}"
                    
                    documents.append(text)
                    metadatas.append({
                        "type": "ì›ê¸€",
                        "name": str(name),
                        "subject": str(subject)[:100],
                        "id": str(row.get('id', ''))
                    })
                    ids.append(f"original_{row.get('id', idx)}")
        except Exception as e:
            print(f"ì›ê¸€ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # ëŒ“ê¸€ ë°ì´í„° ë¡œë“œ
        try:
            csv_path_comment = os.path.join(os.path.dirname(__file__), "..", "20251125_PPMí•™ìŠµìš©ë°ì´í„°_ëŒ“ê¸€.csv")
            self.df_comment = pd.read_csv(csv_path_comment, encoding='utf-8')
            print(f"ëŒ“ê¸€ ë°ì´í„°: {len(self.df_comment)}ê°œ ë¡œë“œë¨")
            
            for idx, row in self.df_comment.iterrows():
                content = self.clean_html(row.get('content', ''))
                name = row.get('name', '')
                writer = row.get('writer', '')
                
                if content and len(content) > 10:
                    text = f"ë‹µë³€: {content}"
                    if name:
                        text = f"[{name}] {text}"
                    if writer:
                        text = f"{text} (ì‘ì„±ì: {writer})"
                    
                    documents.append(text)
                    metadatas.append({
                        "type": "ëŒ“ê¸€",
                        "name": str(name),
                        "writer": str(writer),
                        "id": str(row.get('id', ''))
                    })
                    ids.append(f"comment_{row.get('id', idx)}")
        except Exception as e:
            print(f"ëŒ“ê¸€ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # ë²¡í„°í™” ë° ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬)
        print(f"ì´ {len(documents)}ê°œ ë¬¸ì„œ ë²¡í„°í™” ì¤‘...")
        batch_size = 100
        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i:i+batch_size]
            batch_metas = metadatas[i:i+batch_size]
            batch_ids = ids[i:i+batch_size]
            
            embeddings = self.embedding_model.encode(batch_docs, show_progress_bar=False)
            
            self.collection.add(
                embeddings=embeddings.tolist(),
                documents=batch_docs,
                metadatas=batch_metas,
                ids=batch_ids
            )
            print(f"ì§„í–‰ë¥ : {min(i+batch_size, len(documents))}/{len(documents)}")
        
        print("ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    
    def reload_data(self):
        """ë°ì´í„° ì¬ë¡œë“œ"""
        self.load_data()
    
    def get_openai_response(self, query: str, context: str) -> str:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±"""
        if not self.use_openai:
            return None
        
        try:
            client = openai.OpenAI(api_key=self.openai_api_key)
            prompt = f"""ë‹¤ìŒì€ ê³ ê° ì§€ì› ì§ˆë¬¸ê³¼ ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë‹µë³€ (ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ì‘ì„±):"""
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° ì§€ì› ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"OpenAI API ì˜¤ë¥˜: {e}")
            return None
    
    def get_local_response(self, query: str, context: str) -> str:
        """ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± (ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜)"""
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ì°¾ì•„ì„œ ë°˜í™˜
        lines = context.split('\n\n')
        if lines:
            # ì²« ë²ˆì§¸ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ ì‚¬ìš©
            best_match = lines[0]
            if "ë‹µë³€:" in best_match:
                answer = best_match.split("ë‹µë³€:")[-1].strip()
                return answer[:500]  # ê¸¸ì´ ì œí•œ
            elif "ë‚´ìš©:" in best_match:
                answer = best_match.split("ë‚´ìš©:")[-1].strip()
                return answer[:500]
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    def query(self, query: str, top_k: int = 3) -> Tuple[str, List[dict]]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        self._ensure_initialized()
        # ì¿¼ë¦¬ ë²¡í„°í™”
        query_embedding = self.embedding_model.encode([query])[0]
        
        # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k
        )
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        sources = []
        
        if results['documents'] and len(results['documents'][0]) > 0:
            for i, doc in enumerate(results['documents'][0]):
                context_parts.append(doc)
                if results['metadatas'] and len(results['metadatas'][0]) > i:
                    sources.append({
                        "content": doc[:200] + "...",
                        "metadata": results['metadatas'][0][i]
                    })
        
        context = "\n\n".join(context_parts)
        
        # ì‘ë‹µ ìƒì„±
        if self.use_openai:
            response = self.get_openai_response(query, context)
            if not response:
                response = self.get_local_response(query, context)
        else:
            response = self.get_local_response(query, context)
        
        return response, sources
    
    def extract_company_name(self, query: str) -> Optional[str]:
        """ì¿¼ë¦¬ì—ì„œ ê³ ê°ì‚¬ëª… ì¶”ì¶œ"""
        self._ensure_initialized()
        # ê³ ê°ì‚¬ëª…ì´ ìˆëŠ”ì§€ í™•ì¸
        if self.df_original is not None:
            company_names = self.df_original['name'].unique().tolist()
            # ê¸´ ì´ë¦„ë¶€í„° ë§¤ì¹­ (ë¶€ë¶„ ë§¤ì¹­ ë°©ì§€)
            company_names_sorted = sorted([str(c) for c in company_names if c], key=len, reverse=True)
            
            for company in company_names_sorted:
                if company and company in query:
                    return company
        return None
    
    def get_company_recent_inquiries(self, company_name: str, limit: int = 10) -> List[Dict]:
        """ê³ ê°ì‚¬ë³„ ìµœê·¼ ë¬¸ì˜ê¸€ê³¼ ë‹µë³€ ì¡°íšŒ"""
        if self.df_original is None or self.df_comment is None:
            return []
        
        # í•´ë‹¹ ê³ ê°ì‚¬ì˜ ìµœê·¼ ë¬¸ì˜ê¸€ ì¡°íšŒ
        company_inquiries = self.df_original[
            self.df_original['name'] == company_name
        ].copy()
        
        # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        if 'reg_date' in company_inquiries.columns:
            company_inquiries = company_inquiries.sort_values('reg_date', ascending=False)
        
        results = []
        
        for idx, inquiry in company_inquiries.head(limit).iterrows():
            inquiry_id = str(inquiry.get('id', ''))
            inquiry_content = self.clean_html(inquiry.get('content', ''))
            inquiry_subject = self.clean_html(inquiry.get('subject', ''))
            inquiry_date = inquiry.get('reg_date', '')
            manager_id = inquiry.get('manager_id', '')
            writer = inquiry.get('writer', '')
            
            # í•´ë‹¹ ë¬¸ì˜ê¸€ì˜ ë‹µë³€ ì¡°íšŒ (post_idëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ë¹„êµ)
            replies = self.df_comment[
                (self.df_comment['name'] == company_name) & 
                (self.df_comment['post_id'].astype(str) == str(inquiry_id))
            ].copy()
            
            # ë‹µë³€ë„ ë‚ ì§œìˆœ ì •ë ¬
            if 'reg_date' in replies.columns:
                replies = replies.sort_values('reg_date', ascending=False)
            
            reply_list = []
            for _, reply in replies.iterrows():
                reply_content = self.clean_html(reply.get('content', ''))
                reply_writer = reply.get('writer', '')
                reply_date = reply.get('reg_date', '')
                reply_list.append({
                    'content': reply_content,
                    'writer': reply_writer,
                    'date': reply_date
                })
            
            results.append({
                'id': inquiry_id,
                'subject': inquiry_subject,
                'content': inquiry_content,
                'date': inquiry_date,
                'writer': writer,
                'manager_id': manager_id,
                'replies': reply_list,
                'reply_count': len(reply_list)
            })
        
        return results
    
    def summarize_company_status(self, company_name: str, inquiries: List[Dict]) -> str:
        """ê³ ê°ì‚¬ë³„ ê·¼í™© ìš”ì•½"""
        if not inquiries:
            return f"{company_name}ì˜ ìµœê·¼ ë¬¸ì˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ìµœê·¼ ë¬¸ì˜ê¸€ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        summary_text = f"{company_name}ì˜ ìµœê·¼ ë¬¸ì˜ ë‚´ì—­:\n\n"
        
        for i, inquiry in enumerate(inquiries[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
            summary_text += f"{i}. ë¬¸ì˜ ì œëª©: {inquiry.get('subject', '[ì œëª© ì—†ìŒ]')}\n"
            summary_text += f"   ë¬¸ì˜ ë‚´ìš©: {inquiry.get('content', '')[:200]}...\n"
            
            if inquiry.get('replies'):
                latest_reply = inquiry['replies'][0]
                summary_text += f"   ë‹µë³€ ë‹´ë‹¹ì: {latest_reply.get('writer', 'ë¯¸ìƒ')}\n"
                summary_text += f"   ë‹µë³€ ë‚´ìš©: {latest_reply.get('content', '')[:150]}...\n"
                summary_text += f"   ìƒíƒœ: ë‹µë³€ ì™„ë£Œ ({inquiry.get('reply_count', 0)}ê°œ ë‹µë³€)\n"
            else:
                summary_text += f"   ìƒíƒœ: ë‹µë³€ ëŒ€ê¸° ì¤‘\n"
            
            summary_text += "\n"
        
        # OpenAIë¥¼ ì‚¬ìš©í•´ì„œ ë” ê°„ê²°í•˜ê²Œ ìš”ì•½
        if self.use_openai and self.openai_api_key:
            try:
                client = openai.OpenAI(api_key=self.openai_api_key)
                prompt = f"""ë‹¤ìŒì€ {company_name}ì˜ ìµœê·¼ ê³ ê° ë¬¸ì˜ ë° ë‹µë³€ ë‚´ì—­ì…ë‹ˆë‹¤. 
ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”. ê° ë¬¸ì˜ì— ëŒ€í•´ ì–´ë–¤ ë¬¸ì˜ì˜€ëŠ”ì§€, ë‹´ë‹¹ìê°€ ëˆ„êµ¬ì¸ì§€, í•´ê²°ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ê°„ë‹¨íˆ ì •ë¦¬í•´ì£¼ì„¸ìš”.

{summary_text}

ìœ„ ë‚´ìš©ì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš” (3-5ì¤„ ì •ë„):"""
                
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° ì§€ì› í˜„í™©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"OpenAI ìš”ì•½ ì˜¤ë¥˜: {e}")
                return summary_text
        
        return summary_text
    
    def query_company_status(self, query: str) -> Optional[Tuple[str, List[dict]]]:
        """ê³ ê°ì‚¬ ê·¼í™© ì¡°íšŒ ì „ìš© í•¨ìˆ˜"""
        company_name = self.extract_company_name(query)
        
        if not company_name:
            return None
        
        # ê³ ê°ì‚¬ë³„ ìµœê·¼ ë¬¸ì˜ ì¡°íšŒ
        inquiries = self.get_company_recent_inquiries(company_name, limit=10)
        
        if not inquiries:
            return f"{company_name}ì˜ ìµœê·¼ ë¬¸ì˜ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
        # ìš”ì•½ ìƒì„±
        summary = self.summarize_company_status(company_name, inquiries)
        
        # ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
        sources = []
        for inquiry in inquiries[:3]:  # ìƒìœ„ 3ê°œë§Œ ì†ŒìŠ¤ë¡œ
            sources.append({
                "content": f"ë¬¸ì˜: {inquiry.get('subject', '')}",
                "metadata": {
                    "type": "ê³ ê°ì‚¬ ê·¼í™©",
                    "name": company_name,
                    "id": inquiry.get('id', '')
                }
            })
        
        return summary, sources

